{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sequential processing with LSTM RNNs\n",
    "\n",
    "In this notebook we will be implementing the **LSTM (long short-term memory)** architecture, a type of recurrent neural network. We will then be using this architecture to perform a sequential processing task. This task will be **sequential MNIST (sMNIST)**. sMNIST involves feeding in an MNIST image to a network over time, and then asking the network on the last timestep what label the image had. We will be feeding in the image line by line. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First import all the packages we'll need\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import numpy as np\n",
    "import scipy\n",
    "import matplotlib.pyplot as plt\n",
    "import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to ./data\\MNIST\\raw\\train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9912422/9912422 [00:02<00:00, 4028783.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data\\MNIST\\raw\\train-images-idx3-ubyte.gz to ./data\\MNIST\\raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to ./data\\MNIST\\raw\\train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28881/28881 [00:00<00:00, 28800688.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data\\MNIST\\raw\\train-labels-idx1-ubyte.gz to ./data\\MNIST\\raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to ./data\\MNIST\\raw\\t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1648877/1648877 [00:00<00:00, 3948161.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data\\MNIST\\raw\\t10k-images-idx3-ubyte.gz to ./data\\MNIST\\raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to ./data\\MNIST\\raw\\t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4542/4542 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data\\MNIST\\raw\\t10k-labels-idx1-ubyte.gz to ./data\\MNIST\\raw\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Download the MNIST dataset and create the dataloaders for it\n",
    "# Perform standard data augmentation, but then also re-shape the tensors to get rid of the input channel dimension.\n",
    "\n",
    "transform = transforms.Compose([ \n",
    "    transforms.RandomAffine(degrees=10, translate = (0.05,0.05), scale = (0.95,1.05)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Lambda( lambda x: x.squeeze())\n",
    "])\n",
    "\n",
    "training_data = torchvision.datasets.MNIST(train=True, download = True, root='./data', transform=transform)\n",
    "testing_data = torchvision.datasets.MNIST(train=False, download = True, root='./data', transform=transform)\n",
    "\n",
    "train_dataloader = torch.utils.data.DataLoader(training_data, shuffle=True, batch_size=32)\n",
    "test_dataloader = torch.utils.data.DataLoader(testing_data, shuffle=False, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 28, 28])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# View the shape of a data point\n",
    "next(iter(train_dataloader))[0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basics of the LSTM architecture\n",
    "We will be implementing our own version of the LSTM cell. The LSTM cell will take in a $d$-dimensional input and output a $n$-dimensional output. We will introduce the following notation:\n",
    "1. **The cell input** at time $t$, $x_t \\in \\mathbb{R}^d$ \n",
    "2. **The internal state of the cell** at time $t$, $c_t \\in \\mathbb{R}^n$\n",
    "3. **The output of the cell** at time $t$, $v_t \\in \\mathbb{R}^n$\n",
    "\n",
    "At each time step, the internal state is updated and used to determine the output of the cell. This is done using three gates:\n",
    "1. **Forget gate**: the forget gate $f_t$ determines how to downweight the information currently contained in the internal state\n",
    "2. **Output gate**: the output gate $o_t$ determines how to weight (a transform of) the internal state to generate the output \n",
    "3. **Input gate**: the input gate $i_t$ determines how to weight the input to the cell before using it to update the internal state\n",
    "\n",
    "All the gates are vectors of length $n$ with values between $0$ and $1$. These gates act as *dynamic weights*.\n",
    "\n",
    "## Gates\n",
    "To get the value of each gate, we go through the following steps:\n",
    "1. The gate takes in the input at the current time step $x_t$ and the output of the cell at the previous time step $v_{t-1}$. \n",
    "2. These are then transformed by a linear transform, $W x_t + M v_{t-1} + b$ where $W \\in \\mathbb{R}^{n \\times d}$ and $M \\in \\mathbb{R}^{n \\times n}$ are the weight matrices of the gate and $b \\in \\mathbb{R}^n$ is the bias of the gate\n",
    "3. These are then passed through a *sigmoid* activation function, $\\sigma(x) = 1/(1 + e^{-x})$.\n",
    "\n",
    "Using sub-scripts to denote which gate we're talking about, we arrive at the following equations for the forget gate $f_t$, output gate $o_t$ and input gate $i_t$ at time $t$, \n",
    "$$ f_t = \\sigma( W_f x_t + M_f v_{t-1} + b_f ) $$\n",
    "$$ o_t = \\sigma( W_o x_t + M_o v_{t-1} + b_o ) $$\n",
    "$$ i_t = \\sigma( W_i x_t + M_i v_{t-1} + b_i ) $$\n",
    "\n",
    "## Candidate internal state\n",
    "We need one final ingredient, the candidate internal state, $\\tilde{c}_t \\in \\mathbb{R}^n$. These are the proposed new values for the cell's internal state. We obtain these values in the same way as we obtain the gate values, by performing a linear combination of the input and the previous output, and then passing through a non-linearity $F$. Usually we take $F = \\tanh$. This gives:\n",
    "$$ \\tilde{c}_t = F( W_c x_t + M_c v_{t-1} + b_c ) $$\n",
    "\n",
    "## Putting it together\n",
    "We now have the gates $f_t$, $o_t$, and $i_t$. How are these gates used to update the cell's internal state and generate the cell's output? \n",
    "### Updating the internal state\n",
    "To update the internal state, we go through the following steps:\n",
    "1. Down-weight the previous internal state using the forget gate, $f_t \\odot c_{t-1}$\n",
    "2. Down-weight the candidate internal state via the input gate, $i_t \\odot \\tilde{c}_t$\n",
    "3. Add these together, $c_t = f_t \\odot c_{t-1} + i_t \\odot \\tilde{c}_t$\n",
    "\n",
    "### Generating the output\n",
    "To generate the output at the current time step $v_t$, we go through the following steps:\n",
    "1. Transform the new internal state using a $\\tanh$ non-linearity, $\\tanh(c_t)$ \n",
    "2. Down-weight using the output gate $v_t = o_t \\odot \\tanh(c_t)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the my_LSTM class which inherits from nn.Module. This will be our implemetaion of a single LSTM cell.\n",
    "\n",
    "    # Define the __init__ method. This will take in the input dimension d and output dimension n\n",
    "\n",
    "        # Call the super method and store relevant properties.\n",
    "\n",
    "\n",
    "\n",
    "        # Define a ModuleDict object to store our layers\n",
    "\n",
    "            # Linear transform for the forget gate\n",
    "\n",
    "            # Linear transform for the input gate\n",
    "\n",
    "            # Linear transform for the output gate\n",
    "\n",
    "            # Linear transform for the candidate internal state\n",
    "\n",
    "\n",
    "    # Define the forward method of the LSTM cell. \n",
    "    # This will take (1) the hidden state from the previous time step and (2) the input to the cell at the current time step. \n",
    "    # The method will output (1) the hidden state at the current time step and (2) the output of the cell at the current time step. \n",
    "    \n",
    "        # Concatenate the previous hidden state and the input \n",
    "\n",
    "        # Generate the candidate internal state\n",
    "\n",
    "        # Generate the forget, input, and output gates\n",
    "\n",
    "        # Generate the new internal state\n",
    "\n",
    "        # Generate the output\n",
    "\n",
    "        # Return both the output and the new internal state"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Network architecture\n",
    "We now have define an LSTM cell. How can we build a network around this to perform a task? We actually don't need to do much to augment the LSTM cell. We will just add a linear readout layer. This layer will project from the LSTM output dimension (of size n) to the 10 logits for each class (there are 10 logits because we are doing MNIST). We will also define a forward method that can take in an image, unroll it into a time-series, and then pass it through one line at a time to the LSTM cell. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define our recurrent neural network class (which inherits from nn.Module)\n",
    "\n",
    "    # Define the __init__ method. This will take in the input dimension of the problem d\n",
    "\n",
    "        # Call the super method and store relevant variables. \n",
    "\n",
    "\n",
    "\n",
    "        # Define a ModuleDict object to store our layers\n",
    "\n",
    "            # The LSTM layer\n",
    "\n",
    "            # The output layer. This maps from the hidden state of the LSTM to the logits for each class.\n",
    "\n",
    "    # Define the forward method. This will take in an image to be processed and output a the logits for each class.  \n",
    "\n",
    "        # Iterate through the input time-series, repeatedly passing it through the LSTM cell.\n",
    "\n",
    "        # Pass the final hidden state through the output layer and return the result. These will be the logits for each class."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training our network\n",
    "Now that we've designed the network architecture, we will train the network. This involves our standard steps in PyTorch:\n",
    "1. Define instances of the network, optimiser for that network, and loss function\n",
    "2. For each epoch, iterate through the dataset and perform the following steps:\n",
    "    1. Zero out gradients\n",
    "    2. Perform a forward pass\n",
    "    3. Compute the loss\n",
    "    4. Back-propagate \n",
    "    5. Take a step using the optimiser\n",
    "3. Test the performance of the network on the test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate an instance of our LSTM network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define our optimizer\n",
    "\n",
    "# Define our loss function\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialise a list to store the training loss\n",
    "\n",
    "# Iterate through epochs\n",
    "\n",
    "    # Iterate through the training data loader\n",
    "\n",
    "        # Zero the gradients\n",
    "\n",
    "        # Pass the data through the network\n",
    "\n",
    "        # Calculate the loss\n",
    "\n",
    "        # Backpropagate\n",
    "\n",
    "        # Update the weights\n",
    "\n",
    "        # Append the loss to the list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the training loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the accuracy on the test set"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "comp_neuro",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
